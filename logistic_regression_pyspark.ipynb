{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae816eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:47:35 WARN Utils: Your hostname, harkirat-QEMU-Virtual-Machine resolves to a loopback address: 127.0.1.1; using 192.168.64.16 instead (on interface enp0s6)\n",
      "22/12/26 14:47:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:47:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init('/home/harkirat/spark-3.3.1-bin-hadoop3')\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark=SparkSession.builder.appName('lreg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "404d4dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:48:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName('logreg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa20d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29765a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:51:58 WARN LibSVMFileFormat: 'numFeatures' option not specified, determining the number of features by going though the input. If you know the number in advance, please specify it via 'numFeatures' option to avoid the extra scan.\n"
     ]
    }
   ],
   "source": [
    "df=spark.read.format('libsvm').load('Python-and-Spark-for-Big-Data-master/Spark_for_Machine_Learning/Logistic_Regression/sample_libsvm_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4513674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "|  1.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[151,152,153...|\n",
      "|  0.0|(692,[129,130,131...|\n",
      "|  1.0|(692,[158,159,160...|\n",
      "|  1.0|(692,[99,100,101,...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[127,128,129...|\n",
      "|  1.0|(692,[154,155,156...|\n",
      "|  0.0|(692,[153,154,155...|\n",
      "|  0.0|(692,[151,152,153...|\n",
      "|  1.0|(692,[129,130,131...|\n",
      "|  0.0|(692,[154,155,156...|\n",
      "|  1.0|(692,[150,151,152...|\n",
      "|  0.0|(692,[124,125,126...|\n",
      "|  0.0|(692,[152,153,154...|\n",
      "|  1.0|(692,[97,98,99,12...|\n",
      "|  1.0|(692,[124,125,126...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "669347bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d68d26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 14:54:28 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "22/12/26 14:54:28 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n"
     ]
    }
   ],
   "source": [
    "fitted_log_reg=log_reg.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc0f22a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=fitted_log_reg.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b5b18e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- label: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3900cd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[127,128,129...|[20.3777627514870...|[0.99999999858729...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-21.114014198872...|[6.76550379997544...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-23.743613234669...|[4.87842678719363...|       1.0|\n",
      "|  1.0|(692,[152,153,154...|[-19.192574012715...|[4.62137287300564...|       1.0|\n",
      "|  1.0|(692,[151,152,153...|[-20.125398874693...|[1.81823629114105...|       1.0|\n",
      "|  0.0|(692,[129,130,131...|[20.4890549504180...|[0.99999999873608...|       0.0|\n",
      "|  1.0|(692,[158,159,160...|[-21.082940212819...|[6.97903542820426...|       1.0|\n",
      "|  1.0|(692,[99,100,101,...|[-19.622713503550...|[3.00582577446273...|       1.0|\n",
      "|  0.0|(692,[154,155,156...|[21.1594863606545...|[0.99999999935352...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[28.1036706837249...|[0.99999999999937...|       0.0|\n",
      "|  1.0|(692,[154,155,156...|[-21.054076780103...|[7.18340962962567...|       1.0|\n",
      "|  0.0|(692,[153,154,155...|[26.9648490510157...|[0.99999999999805...|       0.0|\n",
      "|  0.0|(692,[151,152,153...|[32.7855654161371...|[0.99999999999999...|       0.0|\n",
      "|  1.0|(692,[129,130,131...|[-20.331839179672...|[1.47908944089075...|       1.0|\n",
      "|  0.0|(692,[154,155,156...|[21.7830579106544...|[0.99999999965347...|       0.0|\n",
      "|  1.0|(692,[150,151,152...|[-20.640562103727...|[1.08621994880500...|       1.0|\n",
      "|  0.0|(692,[124,125,126...|[22.6400775503720...|[0.99999999985292...|       0.0|\n",
      "|  0.0|(692,[152,153,154...|[38.0712919910887...|           [1.0,0.0]|       0.0|\n",
      "|  1.0|(692,[97,98,99,12...|[-19.830803265607...|[2.44113371550856...|       1.0|\n",
      "|  1.0|(692,[124,125,126...|[-21.016054806032...|[7.46179590487585...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2766f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "171f2df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00957b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_final=final_model.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e855d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_and_labels=fit_final.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ad05c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(692,[98,99,100,1...|[22.7398545406120...|[0.99999999986689...|       0.0|\n",
      "|  0.0|(692,[100,101,102...|[0.80641604351069...|[0.69134525952484...|       0.0|\n",
      "|  0.0|(692,[122,123,124...|[23.1914410475673...|[0.99999999991526...|       0.0|\n",
      "|  0.0|(692,[123,124,125...|[35.3975689628466...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[125,126,127...|[34.6232413868969...|[0.99999999999999...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[17.0388432887613...|[0.99999996017788...|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[37.4473682897191...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[126,127,128...|[26.0113634679192...|[0.99999999999494...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[22.8257552627881...|[0.99999999987784...|       0.0|\n",
      "|  0.0|(692,[127,128,129...|[24.0066483735598...|[0.99999999996249...|       0.0|\n",
      "|  0.0|(692,[129,130,131...|[19.0892201714731...|[0.99999999487543...|       0.0|\n",
      "|  0.0|(692,[151,152,153...|[38.2242533688185...|           [1.0,0.0]|       0.0|\n",
      "|  0.0|(692,[153,154,155...|[23.9970731672093...|[0.99999999996213...|       0.0|\n",
      "|  0.0|(692,[154,155,156...|[11.9331893953943...|[0.99999343130886...|       0.0|\n",
      "|  1.0|(692,[119,120,121...|[-1.3852909703616...|[0.20016059084845...|       1.0|\n",
      "|  1.0|(692,[125,126,127...|[-19.505995876124...|[3.37795317806529...|       1.0|\n",
      "|  1.0|(692,[125,126,153...|[-20.220476133644...|[1.65332713265111...|       1.0|\n",
      "|  1.0|(692,[126,127,128...|[-23.705534271433...|[5.06777442322753...|       1.0|\n",
      "|  1.0|(692,[126,127,128...|[-21.201749986946...|[6.19722085506701...|       1.0|\n",
      "|  1.0|(692,[127,128,154...|[-16.040711334541...|[1.08045711732538...|       1.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_and_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9177b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8af85d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval=BinaryClassificationEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21704627",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc=my_eval.evaluate(predictions_and_labels.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c357e83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef5fce4",
   "metadata": {},
   "source": [
    "# TITANIC DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5fc00e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/12/26 15:49:07 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName('titanic').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58ce08de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('Python-and-Spark-for-Big-Data-master/Spark_for_Machine_Learning/Logistic_Regression/titanic.csv',inferSchema=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8516f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76062d64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c182504",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols=df.select([\n",
    "     'Survived',\n",
    "     'Pclass',\n",
    "     'Sex',\n",
    "     'Age',\n",
    "     'SibSp',\n",
    "     'Parch',\n",
    "     'Fare',\n",
    "     'Embarked'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9e12c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df=my_cols.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbb5c7",
   "metadata": {},
   "source": [
    "## Categorical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5da461ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer, OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c230069",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_indexer=StringIndexer(inputCol='Sex', outputCol='SexIndex')\n",
    "gender_encoder=OneHotEncoder(inputCol='SexIndex', outputCol='SexVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "021c0815",
   "metadata": {},
   "outputs": [],
   "source": [
    "embark_indexer=StringIndexer(inputCol='Embarked', outputCol='EmbarkIndex')\n",
    "embark_encoder=OneHotEncoder(inputCol='EmbarkIndex', outputCol='EmbarkVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12090b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler=VectorAssembler(inputCols=['Pclass',\n",
    "                                     'SexVec',\n",
    "                                     'Age',\n",
    "                                     'SibSp',\n",
    "                                     'Parch',\n",
    "                                     'Fare',\n",
    "                                     'EmbarkVec'],outputCol='features')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04c3d1",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b6129a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce098296",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg=LogisticRegression(featuresCol='features', labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "295b3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[gender_indexer,embark_indexer,\n",
    "                            gender_encoder,embark_encoder,\n",
    "                            assembler,log_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c27581cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test=final_df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "46b4bf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fit_model=pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d846ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=fit_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b33028f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d8911c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
    "                                        labelCol='Survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c63a075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|Survived|prediction|\n",
      "+--------+----------+\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       1.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "|       0|       0.0|\n",
      "+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select('Survived','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f8ac5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7986452082196763"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUC = my_eval.evaluate(results)\n",
    "AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbd0d11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30837d64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
